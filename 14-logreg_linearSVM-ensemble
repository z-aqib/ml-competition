{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":121246,"databundleVersionId":14516487,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import f1_score\nfrom sklearn.base import clone\nfrom scipy.special import expit as sigmoid\n\n# =========================\n# CONFIG\n# =========================\n\nSEED = 42\nN_FOLDS = 5\n\n# TODO: UPDATE THESE PATHS TO MATCH YOUR KAGGLE DATASET\nPATH_TRAIN_P1 = \"/kaggle/input/dss-comp/comp_data/comp_data/train_p1.json\"      # e.g. train_part1.json\nPATH_TRAIN_P2 = \"/kaggle/input/dss-comp/train_part2.json\"      # e.g. train_part2.json\nPATH_TEST     = \"/kaggle/input/dss-comp/comp_data/comp_data/test.json\"\nOUTPUT_CSV    = \"/kaggle/working/submission_linear_logreg_ensemble.csv\"\n\n\n# =========================\n# Helper: Load JSON as list\n# =========================\n\ndef load_json_list(path):\n    \"\"\"\n    Loads a JSON file that contains either:\n    - a list of JSON objects, OR\n    - JSON lines (one object per line)\n    and returns a Python list of dicts.\n    \"\"\"\n    path = Path(path)\n    with path.open(\"r\", encoding=\"utf-8\") as f:\n        text = f.read().strip()\n        if not text:\n            return []\n        # Try parse as a JSON array first\n        try:\n            data = json.loads(text)\n            if isinstance(data, list):\n                return data\n            else:\n                # If it's a single object, wrap it\n                return [data]\n        except json.JSONDecodeError:\n            # Fallback: assume JSON Lines format\n            data = []\n            for line in text.splitlines():\n                line = line.strip()\n                if not line:\n                    continue\n                data.append(json.loads(line))\n            return data\n\n\n# =========================\n# Load & Merge Train Parts\n# =========================\n\ndef build_arrays_from_records(records, has_label=True):\n    \"\"\"\n    From a list of records, build:\n    - X: concatenated [image_embedding (512) + text_embedding (512)] -> shape (n, 1024)\n    - y: labels (if has_label)\n    - ids: record ids (optional / unused for training)\n    \"\"\"\n    X_list = []\n    y_list = []\n    ids_list = []\n\n    for row in records:\n        img = row[\"image_embedding\"]\n        txt = row[\"text_embedding\"]\n\n        # Concatenate image + text embeddings\n        feat = np.asarray(img + txt, dtype=np.float32)\n        X_list.append(feat)\n\n        if has_label:\n            y_list.append(row[\"label\"])\n        if \"id\" in row:\n            ids_list.append(row[\"id\"])\n\n    X = np.vstack(X_list)\n    y = np.array(y_list, dtype=np.int64) if has_label else None\n    return X, y, ids_list\n\n\nprint(\"Loading train_part1...\")\ntrain_p1_records = load_json_list(PATH_TRAIN_P1)\n\nprint(\"Loading train_part2...\")\ntrain_p2_records = load_json_list(PATH_TRAIN_P2)\n\nprint(\"Merging train_part1 + train_part2...\")\ntrain_records = train_p1_records + train_p2_records\n\nprint(\"Total train samples:\", len(train_records))\n\nX_train, y_train, _ = build_arrays_from_records(train_records, has_label=True)\n\nprint(\"Train X shape:\", X_train.shape)\nprint(\"Train y shape:\", y_train.shape)\n\nprint(\"Loading test...\")\ntest_records = load_json_list(PATH_TEST)\nX_test, _, test_ids = build_arrays_from_records(test_records, has_label=False)\n\nprint(\"Test X shape:\", X_test.shape)\nprint(\"Test ids count:\", len(test_ids))\n\n\n# =========================\n# Define Models (Linear + Logistic)\n# =========================\n\n# Logistic Regression (with L2, can tweak C)\nlogreg_base = Pipeline(\n    steps=[\n        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n        (\"logreg\", LogisticRegression(\n            penalty=\"l2\",\n            C=1.0,\n            solver=\"liblinear\",  # good for small-medium data with L2\n            class_weight=\"balanced\",  # handle possible class imbalance\n            max_iter=5000,\n            random_state=SEED,\n        )),\n    ]\n)\n\n# Linear SVM (LinearSVC, a strong linear classifier)\nlinsvm_base = Pipeline(\n    steps=[\n        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n        (\"svc\", LinearSVC(\n            C=1.0,\n            loss=\"squared_hinge\",\n            class_weight=\"balanced\",\n            max_iter=5000,\n            random_state=SEED,\n        )),\n    ]\n)\n\n\n# =========================\n# CV Training Helper\n# =========================\n\ndef fit_cv_and_predict(models_dict, X, y, X_test, n_splits=5, seed=42):\n    \"\"\"\n    models_dict: {\"logreg\": pipeline, \"linsvm\": pipeline}\n    Returns:\n      - oof_preds: dict model_name -> OOF prediction scores (for F1)\n      - test_scores: dict model_name -> aggregated test \"score\" (prob/decision)\n    For logistic, \"score\" is probability of class 1.\n    For LinearSVC, \"score\" is sigmoid(decision_function) to convert to pseudo-prob.\n    \"\"\"\n    skf = StratifiedKFold(\n        n_splits=n_splits,\n        shuffle=True,\n        random_state=seed\n    )\n\n    n_train = X.shape[0]\n    n_test = X_test.shape[0]\n\n    # Initialize containers\n    oof_scores = {name: np.zeros(n_train, dtype=np.float32)\n                  for name in models_dict.keys()}\n    test_scores = {name: np.zeros(n_test, dtype=np.float32)\n                   for name in models_dict.keys()}\n\n    print(\"\\nStarting StratifiedKFold CV...\")\n    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n        print(f\"\\n===== Fold {fold}/{n_splits} =====\")\n        X_tr, X_val = X[tr_idx], X[val_idx]\n        y_tr, y_val = y[tr_idx], y[val_idx]\n\n        for name, base_model in models_dict.items():\n            print(f\"  -> Model: {name}\")\n            model = clone(base_model)\n\n            model.fit(X_tr, y_tr)\n\n            # Predict scores for validation\n            if name == \"logreg\":\n                # Pipeline: scaler + logreg\n                val_proba = model.predict_proba(X_val)[:, 1]\n                test_proba = model.predict_proba(X_test)[:, 1]\n                oof_scores[name][val_idx] = val_proba\n                test_scores[name] += test_proba / n_splits\n\n            else:\n                # LinearSVC: use decision_function -> sigmoid to get pseudo-probs\n                val_dec = model.decision_function(X_val)\n                test_dec = model.decision_function(X_test)\n\n                val_proba = sigmoid(val_dec)\n                test_proba = sigmoid(test_dec)\n\n                oof_scores[name][val_idx] = val_proba\n                test_scores[name] += test_proba / n_splits\n\n            # Compute fold F1 at 0.5 threshold\n            val_pred = (oof_scores[name][val_idx] >= 0.5).astype(int)\n            fold_f1 = f1_score(y_val, val_pred, average=\"macro\")\n            print(f\"    Fold F1_macro ({name}): {fold_f1:.5f}\")\n\n    # Print overall CV F1\n    print(\"\\n===== Overall CV results =====\")\n    for name in models_dict.keys():\n        preds = (oof_scores[name] >= 0.5).astype(int)\n        f1 = f1_score(y, preds, average=\"macro\")\n        print(f\"Model {name}: CV F1_macro = {f1:.5f}\")\n\n    # Simple ensemble: average scores of all models\n    all_model_scores = np.vstack([test_scores[name] for name in models_dict.keys()])\n    ensemble_scores = np.mean(all_model_scores, axis=0)\n\n    return oof_scores, test_scores, ensemble_scores\n\n\n# =========================\n# Run CV & Build Submission\n# =========================\n\nmodels = {\n    \"logreg\": logreg_base,\n    \"linsvm\": linsvm_base,\n}\n\noof_scores, test_scores, ensemble_scores = fit_cv_and_predict(\n    models_dict=models,\n    X=X_train,\n    y=y_train,\n    X_test=X_test,\n    n_splits=N_FOLDS,\n    seed=SEED,\n)\n\n# Final prediction from ensemble: threshold 0.5\ntest_pred_final = (ensemble_scores >= 0.5).astype(int)\n\n# Build submission DF\nsub_df = pd.DataFrame({\n    \"row_id\": test_ids,    # test.json uses sequential integer ids\n    \"target\": test_pred_final,\n})\n\n# Sort by row_id to be safe\nsub_df = sub_df.sort_values(\"row_id\").reset_index(drop=True)\n\nsub_df.to_csv(OUTPUT_CSV, index=False)\nprint(f\"\\nSaved submission to: {OUTPUT_CSV}\")\nprint(sub_df.head())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T12:07:09.374951Z","iopub.execute_input":"2025-11-17T12:07:09.375311Z","iopub.status.idle":"2025-11-17T12:08:18.476267Z","shell.execute_reply.started":"2025-11-17T12:07:09.375282Z","shell.execute_reply":"2025-11-17T12:08:18.475017Z"}},"outputs":[{"name":"stdout","text":"Loading train_part1...\nLoading train_part2...\nMerging train_part1 + train_part2...\nTotal train samples: 3061\nTrain X shape: (3061, 1024)\nTrain y shape: (3061,)\nLoading test...\nTest X shape: (500, 1024)\nTest ids count: 500\n\nStarting StratifiedKFold CV...\n\n===== Fold 1/5 =====\n  -> Model: logreg\n    Fold F1_macro (logreg): 0.65142\n  -> Model: linsvm\n    Fold F1_macro (linsvm): 0.62033\n\n===== Fold 2/5 =====\n  -> Model: logreg\n    Fold F1_macro (logreg): 0.67400\n  -> Model: linsvm\n    Fold F1_macro (linsvm): 0.64271\n\n===== Fold 3/5 =====\n  -> Model: logreg\n    Fold F1_macro (logreg): 0.63211\n  -> Model: linsvm\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"    Fold F1_macro (linsvm): 0.62328\n\n===== Fold 4/5 =====\n  -> Model: logreg\n    Fold F1_macro (logreg): 0.62170\n  -> Model: linsvm\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"    Fold F1_macro (linsvm): 0.57017\n\n===== Fold 5/5 =====\n  -> Model: logreg\n    Fold F1_macro (logreg): 0.60126\n  -> Model: linsvm\n    Fold F1_macro (linsvm): 0.58449\n\n===== Overall CV results =====\nModel logreg: CV F1_macro = 0.63680\nModel linsvm: CV F1_macro = 0.60886\n\nSaved submission to: /kaggle/working/submission_linear_logreg_ensemble.csv\n   row_id  target\n0       1       0\n1       2       0\n2       3       0\n3       4       0\n4       5       0\n","output_type":"stream"}],"execution_count":2}]}